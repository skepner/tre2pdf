#! /usr/bin/env python
# -*- Python -*-
# license
# Copyright (c) 2016, The Center For Pathogen Evolution, Department of Zoology, University of Cambridge, UK
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are met:
#     1. Redistributions of source code must retain the above copyright
#        notice, this list of conditions and the following disclaimer.
#     2. Redistributions in binary form must reproduce the above copyright
#        notice, this list of conditions and the following disclaimer in the
#        documentation and/or other materials provided with the distribution.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
# ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
# WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
# DISCLAIMED. IN NO EVENT SHALL THE CENTER FOR PATHOGEN EVOLUTION BE LIABLE FOR ANY
# DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
# (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
# LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
# ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
# SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
# license.

"""

"""

from __future__ import print_function

import sys
if sys.version_info.major != 2:
    print("This script must be executed with python 2")
    exit(1)

import os, re, urllib, json, traceback, pprint, logging, datetime

# ======================================================================

def main(args):
    exit_code = 0
    try:
        sequences = translate_to_amino_acid(decode_names(load_fasta(args.fasta[0])))
        subtype = detect_subtype(sequences)
        sequences = align(sequences, subtype)
        write(sequences, args.output[0])
    except Exception as err:
        print('ERROR:', err, traceback.format_exc())
        exit_code = 1
    return exit_code

# ======================================================================

SIGNAL_PEPTIDE = {
    "H3": [                               # all from http://signalpeptide.com/
        "MKTIIALCYILCLVFA","MKTIIALSHIFCLVLG","MKTIIALSYIFCLAFA","MKTIIALSYIFCLAFG","MKTIIALSYIFCLALG",
        "MKTIIALSYIFCLVFA","MKTIIALSYIFCLVLG","MKTIIALSYIFCQVFA","MKTIIALSYIFCQVLA","MKTIIALSYILCLVFA",
        "MKTIIALSYISCLVFA","MKTIIVLSCFFCLAFS","MKTLIALSYIFCLVLG","MKTTTILILLTHWVHS"
        ],
    "H1": [
        "MKVKLLVLLCTFTATYA","MKVKLLVLLCTFSATYA", # H1seas, http://signalpeptide.com/
        "MKAILVVLLYTFATANA",              # H1pdm
        ],
    "B": [
        "MKAIIVLLMVVTSNA",                # http://repository.kulib.kyoto-u.ac.jp/dspace/bitstream/2433/49327/1/8_1.pdf
        "MVVTSNA",                        # http://signalpeptide.com/
        ],

}

SIGNAL_PEPTIDE_LEN = {"H3": 16, "H1": 17, "B": 7}

GOOD_INFIXES = {
    "H3": [
        {"infix": "ATLCLGHHAV", "shift": 10},
        ],
    "H1": [
        {"infix": "DTLCIGYHA", "shift": 0},
        {"infix": "DTICIGYHANN", "shift": 0},
        {"infix": "DTICMGYHANN", "shift": 0},
        {"infix": "GYHANNSTDTV", "shift": 5},
        {"infix": "GYHANNSADTV", "shift": 5},
        ],
    "B": [
        {"infix": "RICT", "shift": 1, "check": [{"offset": 40, "seq": "FANL"}]},
        {"infix": "SICT", "shift": 1, "check": [{"offset": 40, "seq": "FANL"}]},
        {"infix": "FANLKG", "shift": 40, "check": [{"offset": 58, "seq": "NCTDLDVAL"}]},
        ],
}

EXCLUDE = {
    "H3": [],
    "H1": [],
    "B":  [
        {"seq": "MLPSTIQ", "type": "neuraminidase"},
        {"seq": "MADNMTT", "type": "ns1"},
        {"seq": "MANNNMT", "type": "ns1"},
        ],
}

def separate_short(r, min_len):
    for name, data in r["bad"].items():
        if len(data["sequence"]) < min_len:
            data["shift"] = "short"
            r["short"][name] = data
    cleanup(r)

def separate_by_signal_peptide(signal_peptide, r, start_len):
    for name, data in r["bad"].items():
        offset = -1
        for sp in signal_peptide:
            offset = data["sequence"].find(sp)
            if offset >= 0:
                data["signal_peptide_len"] = len(sp)
                data["shift"] = - offset - data["signal_peptide_len"]
                r["good_start"].add(data["sequence"][offset + len(sp) : offset + len(sp) + start_len])
                break
        if offset >= 0:
            r["good"][name] = data
    cleanup(r)

def separate_by_mismatched_signal_peptide_at_beginning(signal_peptide, signal_peptide_len, r):
    if r["good_start"]:
        for name, data in r["bad"].items():
            sp_len, diff_sp = differences(signal_peptide, data["sequence"])
            gs_len, diff_gs = differences(r["good_start"], data["sequence"][sp_len:])
            # print("{:2d} {:2d} {} {}".format(diff_sp, diff_gs, data["sequence"][:signal_peptide_len], data["sequence"][signal_peptide_len:signal_peptide_len + 16]))
            if diff_gs < 2 and diff_sp < 8:
                data["signal_peptide_len"] = sp_len
                data["shift"] = - data["signal_peptide_len"]
                r["good"][name] = data
        cleanup(r)

def separate_by_good_start(r):
    for name, data in r["bad"].items():
        offset = -1
        for gs in r["good_start"]:
            o = data["sequence"].find(gs)
            if o >= 0 and (offset < 0 or o < offset):
                offset = o
        if offset >= 0:
            data["shift"] = - offset
            data["signal_peptide_len"] = 0
            r["good"][name] = data
    cleanup(r)

def separate_by_good_infixes(good_infixes, r):

    def check(data, offset, gi):
        good = True
        if gi.get("check"):
            for c in gi["check"]:
                b = offset - gi["shift"] + c["offset"]
                e = b + len(c["seq"])
                if data["sequence"][b:e] != c["seq"]:
                    good = False
                    break
        return good

    for name, data in r["bad"].items():
        for gi in good_infixes:
            offset = data["sequence"].find(gi["infix"])
            if offset >= 0 and check(data, offset, gi):
                data["shift"] = - offset + gi["shift"]
                data["signal_peptide_len"] = 0
                r["good"][name] = data
                break
    cleanup(r)

def separate_excluded(prefixes, r):
    for name, data in r["bad"].items():
        for p in prefixes:
            if data["sequence"][:len(p["seq"])] == p["seq"]:
                data["shift"] = p["type"]
                r[p["type"]][name] = data
                break
    cleanup(r)

def cleanup(r):
    for name in list(r["bad"]):
        if r["bad"][name].get("shift") is not None:
            del r["bad"][name]

def report(prefix, r):
    print("{}: good: {}  bad: {} short: {} total: {}".format(prefix, len(r["good"]), len(r["bad"]), len(r["short"]), len(r["good"]) + len(r["bad"]) + len(r["short"])))

def differences(prefixes, seq):
    """returns tuple (prefix_len, difference)"""

    def diff(prefix):
        return sum(0 if prefix[p] == seq[p] else 1 for p in range(len(prefix)))

    diffs = sorted(((len(prefix), diff(prefix)) for prefix in prefixes), key=lambda e: e[1])
    return diffs[0]

def shift_good(r):
    min_shift = min(data["shift"] for data in r["good"].values())
    for name, data in r["good"].items():
        nx = data["shift"] - min_shift
        if nx > 0:
            data["prefix"] = "x" * nx
        elif nx < 0:
            raise RuntimeError("Negative resulting shift, min_shift:{} {} {}".format(min_shift, name, data))
        else:
            data["prefix"] = ""
        # print(data["prefix"], data["sequence"][:64], sep="")

def align(sequences, subtype):
    signal_peptide = SIGNAL_PEPTIDE[subtype]
    signal_peptide_len = SIGNAL_PEPTIDE_LEN[subtype]
    r = {"good": {}, "bad": sequences, "good_start": set(), "short": {}, "neuraminidase": {}, "ns1": {}}
    separate_short(r, 100)
    report("separate_short good", r)
    separate_by_signal_peptide(signal_peptide, r, 16)
    report("separate_by_signal_peptide", r)
    separate_by_good_start(r)
    report("separate_by_good_start", r)
    separate_by_mismatched_signal_peptide_at_beginning(signal_peptide, signal_peptide_len, r)
    report("separate_by_mismatched_signal_peptide_at_beginning", r)
    separate_excluded(EXCLUDE[subtype], r)
    report("separate_neuraminidase", r)
    separate_by_good_infixes(GOOD_INFIXES[subtype], r)
    report("separate_by_good_infixes", r)
    shift_good(r)

    print("\nGOOD_START\n\t", "\n\t".join(sorted(r["good_start"])), sep="")
    print("\nBAD")
    for name in sorted(r["bad"], key=lambda n: r["bad"][n]["sequence"]):
        data = r["bad"][name]
        #print(data["sequence"][:16], data["sequence"][16:32], name, data["sequence"])
        print(data["sequence"][:signal_peptide_len], data["sequence"][signal_peptide_len:signal_peptide_len + 64], name)
    return r

# ----------------------------------------------------------------------

def write(r, output):

    def write_entry(f, name, prefix, sequence):
        f.write(">")
        f.write(name)
        f.write("\n")
        f.write(prefix)
        f.write(sequence)
        f.write("\n")

    with open(output, "w") as f:
        for name, data in r["good"].items():
            write_entry(f, name, data["prefix"], data["sequence"])
        f.write("\n==== BAD ====\n\n")
        for name, data in r["bad"].items():
            write_entry(f, name, "", data["sequence"])
        f.write("\n==== SHORT ====\n\n")
        for name, data in r["short"].items():
            write_entry(f, name, "", data["sequence"])

# ----------------------------------------------------------------------

CODON_TO_PROTEIN = {
    'UGC': 'C', 'GTA': 'V', 'GTG': 'V', 'CCT': 'P', 'CUG': 'L', 'AGG': 'R', 'CTT': 'L', 'CUU': 'L',
    'CTG': 'L', 'GCU': 'A', 'CCG': 'P', 'AUG': 'M', 'GGC': 'G', 'UUA': 'L', 'GAG': 'E', 'UGG': 'W',
    'UUU': 'F', 'UUG': 'L', 'ACU': 'T', 'TTA': 'L', 'AAT': 'N', 'CGU': 'R', 'CCA': 'P', 'GCC': 'A',
    'GCG': 'A', 'TTG': 'L', 'CAT': 'H', 'AAC': 'N', 'GCA': 'A', 'GAU': 'D', 'UAU': 'Y', 'CAC': 'H',
    'AUA': 'I', 'GUC': 'V', 'TCG': 'S', 'GGG': 'G', 'AGC': 'S', 'CTA': 'L', 'GCT': 'A', 'CCC': 'P',
    'ACC': 'T', 'GAT': 'D', 'TCC': 'S', 'UAC': 'Y', 'CAU': 'H', 'UCG': 'S', 'CAA': 'Q', 'UCC': 'S',
    'AGU': 'S', 'TTT': 'F', 'ACA': 'T', 'ACG': 'T', 'CGC': 'R', 'TGT': 'C', 'CAG': 'Q', 'GUA': 'V',
    'GGU': 'G', 'AAG': 'K', 'AGA': 'R', 'ATA': 'I', 'TAT': 'Y', 'UCU': 'S', 'TCA': 'S', 'GAA': 'E',
    'AGT': 'S', 'TCT': 'S', 'ACT': 'T', 'CGA': 'R', 'GGT': 'G', 'TGC': 'C', 'UGU': 'C', 'CUC': 'L',
    'GAC': 'D', 'UUC': 'F', 'GTC': 'V', 'ATT': 'I', 'TAC': 'Y', 'CUA': 'L', 'TTC': 'F', 'GTT': 'V',
    'UCA': 'S', 'AUC': 'I', 'GGA': 'G', 'GUG': 'V', 'GUU': 'V', 'AUU': 'I', 'CGT': 'R', 'CCU': 'P',
    'ATG': 'M', 'AAA': 'K', 'TGG': 'W', 'CGG': 'R', 'AAU': 'N', 'CTC': 'L', 'ATC': 'I',
    # stops
    'TAA': '*', 'UAA': '*', 'TAG': '*', 'UAG': '*', 'TGA': '*', 'UGA': '*', 'TAR': '*', 'TRA': '*', 'UAR': '*', 'URA': '*',
    }

def translate_to_amino_acid(sequences, min_offset=0, max_offset=2):

    def translate(seq):
        best = ""
        for offset in range(min_offset, max_offset + 1):
            trans = translate_at(seq, offset)
            if len(trans) > len(best):
                best = trans
        return best

    def translate_at(seq, offset):
        r = "".join(CODON_TO_PROTEIN.get(codon, "X") for codon in (seq[i:i+3] for i in range(offset, len(seq), 3)))
        stop = r.find("*")
        if stop >= 0:
            r = r[:stop]
        return r

    for name in sequences:
        sequences[name]["sequence"] = translate(sequences[name]["sequence"])
    logging.info('{} sequences translated to amino acid'.format(len(sequences)))
    return sequences

# ----------------------------------------------------------------------

sReSubtype = re.compile(r'^(?:B/|A\((H3|H1))')

def detect_subtype(sequences):
    for name in sequences:
        m = sReSubtype.match(name)
        # logging.info('{} {}'.format(name, m))
        if m:
            subtype = m.group(1) or "B"
            logging.info('Subtype: {} ({})'.format(subtype, name))
            return subtype
    raise RuntimeError("cannot detect subtype by sequence names")

# ----------------------------------------------------------------------

class FastaReaderError (Exception):
    pass

def load_fasta(filename):
    sequences = {}

    def read_entries(source):
        sequence = ''
        raw_name = None
        for line_no, line in enumerate(source, start=1):
            try:
                line = line.strip()
            except:
                raise FastaReaderError('{filename}:{line_no}: cannot decode line'.format(filename=filename, line_no=line_no))
            if not line or line[0] == ';':               # empty or comment line
                pass
            elif line[0] == '>':
                if raw_name:
                    if not sequence:
                        raise FastaReaderError('{filename}:{line_no}: {raw_name!r} without sequence'.format(raw_name=raw_name, filename=filename, line_no=line_no))
                    sequence = check_sequence(sequence, line_no)
                    yield {'raw_name': raw_name, 'sequence': sequence.upper()}
                sequence = ''
                raw_name = line[1:]
            else:
                if not raw_name:
                    raise FastaReaderError('{filename}:{line_no}: sequence without name'.format(filename=filename, line_no=line_no))
                sequence += line
        if raw_name:
            if not sequence:
                raise FastaReaderError('{filename}:EOF: {raw_name!r} without sequence'.format(raw_name=raw_name, filename=filename))
            sequence = check_sequence(sequence, line_no)
            yield {'raw_name': raw_name, 'sequence': sequence.upper()}

    sReSequence = re.compile(r"^[A-Za-z\-~:\*\.]+$")

    def check_sequence(sequence, line_no):
        sequence = sequence.replace("/", "-")   # / found H1pdm sequences
        if not sReSequence.match(sequence):
            raise FastaReaderError('{filename}:{line_no}: invalid sequence read: {sequence}'.format(sequence=sequence, filename=filename, line_no=line_no))
        return sequence

    def add_entry(entry, ignore_duplicates=True, report_duplicates=False):
        if entry['raw_name'] in sequences and entry['sequence'] != sequences[entry['raw_name']]:
            if not ignore_duplicates:
                raise FastaReaderError("Duplicating name: {}, different sequences.".format(entry['raw_name']))
            elif report_duplicates:
                logging.warning("Duplicating name: {}, different sequences.".format(entry['raw_name']))
        else:
            sequences[entry['raw_name']] = {"sequence": entry['sequence']}

    for entry in read_entries(open(filename)):
        add_entry(entry)
    logging.info("{} unique sequence names read from {}".format(len(sequences), filename))
    return sequences

# ----------------------------------------------------------------------

sReNameDecoder = re.compile(r'%([0-9A-Fa-f][0-9A-Fa-f])')

def decode_names(sequences):

    def replace(match):
        c = int(match.group(1), 16)
        return chr(c)

    def decode_name(name):
        return sReNameDecoder.sub(replace, name)

    return {decode_name(n): s for n, s in sequences.items()}

# ----------------------------------------------------------------------

try:
    import argparse
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument('fasta', nargs=1, help='Fasta file to process.')
    parser.add_argument('output', nargs=1, help='Output file name.')
    parser.add_argument('--debug', action='store_true', dest='debug', default=False, help='Enable debugging output.')
    args = parser.parse_args()
    logging_format = "%(levelname)s: %(message)s"
    if args.debug:
        logging.basicConfig(level=logging.DEBUG, format=logging_format)
    else:
        logging.basicConfig(level=logging.INFO, format=logging_format)
    exit_code = main(args)
except Exception as err:
    logging.error('{}\n{}'.format(err, traceback.format_exc()))
    exit_code = 1
exit(exit_code)

# ======================================================================
### Local Variables:
### eval: (if (fboundp 'eu-rename-buffer) (eu-rename-buffer))
### End:
